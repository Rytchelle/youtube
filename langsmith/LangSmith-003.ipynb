{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e961592-1bad-4213-bdb1-162b8fc1892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langsmith import Client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Demo LangSmith 03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b119f2e0-16f6-4377-8952-827b01662f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad81876a-16bc-4b57-8772-f3ee83f978d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "\n",
    "dataset_name = \"QA Example Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"question\": \"O que é LangChain?\"},\n",
    "        {\"question\": \"O que é LangSmith?\"},\n",
    "        {\"question\": \"O que é OpenAI?\"},\n",
    "        {\"question\": \"O que é Google?\"},\n",
    "        {\"question\": \"O que é Mistral?\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"answer\": \"Um framework para desenvolver aplicações LLM\"},\n",
    "        {\"answer\": \"Uma plataforma de observabilidade para aplicações LLM\"},\n",
    "        {\"answer\": \"Uma empresa que cria LLMs\"},\n",
    "        {\"answer\": \"Uma empresa de tecnologia conhecida por dominar buscas\"},\n",
    "        {\"answer\": \"Uma empresa que cria LLMs\"},\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04873392-cb2f-420f-a908-54847f2be4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"\"Você é um professor especialista em avaliar respostas de alunos.\n",
    "Você está avaliando a seguinte pergunta:\n",
    "{query}\n",
    "Aqui está a resposta real:\n",
    "{answer}\n",
    "Você está avaliando a seguinte resposta prevista:\n",
    "{result}\n",
    "Responda com CORRETO ou INCORRETO:\n",
    "Avaliação:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE\n",
    ")\n",
    "eval_llm = ChatOpenAI(temperature=0.0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0948d29-de99-4313-bada-026ba61cbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "def evaluate_length(run: Run, example: Example) -> dict:\n",
    "    prediction = run.outputs.get(\"output\") or \"\"\n",
    "    required = example.outputs.get(\"answer\") or \"\"\n",
    "    score = int(len(prediction) < 2 * len(required))\n",
    "    return {\"key\":\"length\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58b7808c-c265-49ca-9313-591ebfa0f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.Client()\n",
    "\n",
    "def my_app(question):\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Responda às perguntas dos usuários de forma curta e concisa (uma frase curta).\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "    ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d788c6-17e1-4418-b1a1-dcf863439884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langsmith_app(inputs):\n",
    "    output = my_app(inputs[\"question\"])\n",
    "    return {\"output\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbf85831-86c9-40fc-ba96-6aae91db3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-4o-mini-05271edc' at:\n",
      "https://smith.langchain.com/o/f8237160-33a4-53f2-b52e-75bb63c1854e/datasets/1de0865d-d403-4018-9035-f34a74c11209/compare?selectedSessions=a4223239-f3f5-4c7a-aece-301bd7075774\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50bd1824a5e4d0f87dbc79a37aa602b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    langsmith_app,\n",
    "    data=dataset_name,\n",
    "    evaluators=[evaluate_length, qa_evaluator],\n",
    "    experiment_prefix=\"openai-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0223445f-2193-4856-9e72-fbe0d06edc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'openai-gpt-3.5-turbo-1097f19a' at:\n",
      "https://smith.langchain.com/o/f8237160-33a4-53f2-b52e-75bb63c1854e/datasets/1de0865d-d403-4018-9035-f34a74c11209/compare?selectedSessions=23acec67-9e0a-4230-b3ac-0fab4a6aa4b4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72158547d3e544bcb8c1017e338be595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.Client()\n",
    "\n",
    "def my_app_2(question):\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Responda às perguntas dos usuários de forma curta e concisa (uma frase curta).\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "def langsmith_app_2(inputs):\n",
    "    output = my_app_2(inputs[\"question\"])\n",
    "    return {\"output\": output}\n",
    "\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    langsmith_app_2, \n",
    "    data=dataset_name, \n",
    "    evaluators=[evaluate_length, qa_evaluator], \n",
    "    experiment_prefix=\"openai-gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faa9bd-30eb-476c-b260-c5f4872156da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
